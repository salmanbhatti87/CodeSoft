{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKgVnHPo94Fj",
        "outputId": "009a7140-00f4-44ca-e1c7-3174f2349d65"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "honwEJTW-E8V",
        "outputId": "03e516fa-c5d4-4e40-f749-f3089cf5a3e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "9oRQgzVx-Go1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "XRlKsPJK-KvZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download kartik2112/fraud-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrqVndl8-UAt",
        "outputId": "ca2aaa65-141c-48fd-fe4b-4de3b6767d56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fraud-detection.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/fraud-detection.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSK7AJuz-lwq",
        "outputId": "edc5281f-0eb0-4172-b498-437c6352d2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace fraudTest.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pingouin"
      ],
      "metadata": {
        "id": "4UGpCwxP_Koc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasist"
      ],
      "metadata": {
        "id": "I1y2K7W2_agV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "id": "j2NbmEAW_puI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns',None)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(18,8)},style='darkgrid')\n",
        "sns.set_palette('rocket')\n",
        "from time import time\n",
        "import pingouin\n",
        "from scipy.stats import ttest_ind\n",
        "from datasist.structdata import detect_outliers\n",
        "from geopy.distance import great_circle\n",
        "from category_encoders import WOEEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import *\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "U7-1tzDO_B6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(r\"/content/fraudTrain.csv\")\n",
        "train.head()"
      ],
      "metadata": {
        "id": "34vfxE2A_y42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(r\"/content/fraudTest.csv\")\n",
        "test.head()"
      ],
      "metadata": {
        "id": "0F_alsw4ABC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The test data also contains is_fraud it's not separated to test our model\n",
        "#So we will concat. them togther to clean them, then make our predictions on test data without is_fraud\n",
        "train['split'] = 'train'\n",
        "test['split']='test'\n",
        "df = pd.concat([train,test],axis=0).reset_index(drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5KNrjleKAL4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "df.info()"
      ],
      "metadata": {
        "id": "pitZykXMAYYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check Nulls\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Y7N7veYUAnn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "Iu5KqJ-XAv9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We found no duplicated rows, so each row is a unique transaction\n",
        "df.columns"
      ],
      "metadata": {
        "id": "37Y2p6psA6RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop unnecessary columns\n",
        "#We will drop lcoation of customer as we will get the distance between\n",
        "#Merchant and customer location later\n",
        "df.drop(columns=['Unnamed: 0','street','state','first','last','trans_num','unix_time'],inplace=True)"
      ],
      "metadata": {
        "id": "unKV2_4QA9S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "D0Bh3FflBD0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change date type\n",
        "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], format='%Y-%m-%d %H:%M:%S')"
      ],
      "metadata": {
        "id": "tMpbXi3RBJJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['hour'] = df['trans_date_trans_time'].dt.hour\n",
        "df['day'] = df['trans_date_trans_time'].dt.day_name()\n",
        "df['month'] = df['trans_date_trans_time'].dt.month"
      ],
      "metadata": {
        "id": "nNguJqNWB18B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clean merchant column\n",
        "df['merchant'] = df['merchant'].apply(lambda x : x.replace('fraud_',''))"
      ],
      "metadata": {
        "id": "hzEZ4C0YB-F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['merchant']].head()"
      ],
      "metadata": {
        "id": "-RBOCdvxCFRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Date of birth --> Age of customer\n",
        "df['dob'] = pd.to_datetime(df['dob'],format='%Y-%m-%d %H:%M:%S')\n",
        "df['age'] = (df['trans_date_trans_time'].dt.year - df['dob'].dt.year).astype(int)\n",
        "df.drop(columns='dob',inplace=True)"
      ],
      "metadata": {
        "id": "-Ff68tpkCMHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Location between customer home and merchant\n",
        "df['distance_km'] = df.apply(lambda col : round(great_circle((col['lat'],col['long']),\n",
        "                                         (col['merch_lat'],col['merch_long'])).kilometers,2),axis=1)"
      ],
      "metadata": {
        "id": "uTe0VeHqCdoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['lat','long','merch_lat','merch_long'],inplace=True)\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "y7LJRDRYDbVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary stats\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "VsjEaR7BDiV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='object').T"
      ],
      "metadata": {
        "id": "vcbDE0tLDreB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check corr between numeric values\n",
        "sns.heatmap(df.select_dtypes(include='number').corr(),\n",
        "            annot=None,cmap='coolwarm',fmt='.2f',linewidths=0.5,cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IBLRMfEmDy8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We can't detect a clear corr between features\n",
        "df.select_dtypes(include='number').corr()"
      ],
      "metadata": {
        "id": "42SFWx7UD55T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to visualize determined data\n",
        "def bar_plot(col):\n",
        "    def top_frauds(col):\n",
        "        return pd.DataFrame(df.loc[df['is_fraud'] == 1, [col]].value_counts()).reset_index().head(10)\n",
        "\n",
        "    ax = sns.barplot(data=top_frauds(col), x=col, y=top_frauds(col)[0], palette='bone')  # Use the column name directly\n",
        "    ax.bar_label(ax.containers[0])\n",
        "    plt.title(f'Top 10 Frauds | {col}', fontsize=16, fontweight='bold')\n",
        "    plt.xticks(rotation=45, fontweight='bold')"
      ],
      "metadata": {
        "id": "VVZinzVjECAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(17,15))\n",
        "for idx,val in enumerate(['cc_num','merchant','category','city','job','age']):\n",
        "    plt.subplot(3,2,idx+1)\n",
        "    bar_plot(val)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "CIQumo5vEYK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Amount\n",
        "sns.catplot(data=df,x='amt',col='is_fraud',kind='box',sharex=False)"
      ],
      "metadata": {
        "id": "fKguw5V-Hh8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We detect a huge number of outliers in the amounts of genuine transaction\n",
        "#We will handle that in the scaling process since we can't remove them\n",
        "#Because they represent real data\n",
        "def pie_bar_plot(col):\n",
        "    print(df[col].value_counts())\n",
        "    sns.set_palette('viridis')\n",
        "    fig,axs=plt.subplots(1,2)\n",
        "    axs[0].pie(df[col].value_counts().values.tolist(),autopct='%.2f%%',textprops={'fontsize':25},explode=[0,0.05],shadow=True)\n",
        "    sns.countplot(data=df,x=col,ax=axs[1])\n",
        "    fig.legend(labels=df[col].value_counts().index.tolist(),loc='upper left',fontsize=20)\n",
        "    fig.tight_layout()\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "qXYmlMn6HsEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gender\n",
        "pie_bar_plot('gender')"
      ],
      "metadata": {
        "id": "t9s7R2FmH2xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Frauds\n",
        "pie_bar_plot('is_fraud')"
      ],
      "metadata": {
        "id": "f9GZ7BOBH6Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We discover that is_fraud column is imbalanced.\n",
        "#So will fix that later\n",
        "#What is the most month|day|hour frauds occur?\n",
        "fig,axs = plt.subplots(3,2)\n",
        "#Month\n",
        "df.loc[df['is_fraud']==1,'month'].value_counts().sort_index().plot(kind='line',ax=axs[0,0],marker='o',fontsize=15)\n",
        "axs[0,0].set_xticks(range(0,12))\n",
        "df.loc[df['is_fraud']==1,'month'].value_counts(ascending=True).plot(kind='bar',ax=axs[0,1],fontsize=15)\n",
        "fig.suptitle('Fraudulent Analysis', fontsize=18, fontweight='bold')\n",
        "##Day\n",
        "df.loc[df['is_fraud']==1,'day'].value_counts(ascending=True).plot(kind='line',ax=axs[1,0],marker='o',fontsize=15)\n",
        "df.loc[df['is_fraud']==1,'day'].value_counts(ascending=True).plot(kind='bar',ax=axs[1,1],fontsize=15)\n",
        "#Hour\n",
        "df.loc[df['is_fraud']==1,'hour'].value_counts().sort_index().plot(kind='line',ax=axs[2,0],marker='o',fontsize=15)\n",
        "axs[2,0].set_xticks(range(0,24))\n",
        "df.loc[df['is_fraud']==1,'hour'].value_counts(ascending=True).plot(kind='bar',ax=axs[2,1],fontsize=15)\n",
        "fig.suptitle('Fraudulent Analysis', fontsize=20, fontweight='bold')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "WACQJuMtIBFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We conclude that most fraud transactions occurs:¶\n",
        "# On March, Sunday At 11 PM\n",
        "df.loc[df['is_fraud']==1,['gender']].value_counts()\n",
        "#Males and females exposed to fraud equally (approximately)"
      ],
      "metadata": {
        "id": "7OvoPam2IMEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data=df,x='is_fraud', y='city_pop', ci=None)\n",
        "plt.title('Average city_population for Fraud and Non-Fraud Cases',fontsize=15)\n",
        "plt.show()\n",
        "\n",
        "fraud_population = df[df['is_fraud'] == 1]['city_pop']\n",
        "non_fraud_population = df[df['is_fraud'] == 0]['city_pop']\n",
        "t_stat, p_value = ttest_ind(fraud_population, non_fraud_population)\n",
        "print(f'T-test: t-statistic = {round(t_stat,3)}, p-value = {round(p_value,3)}, p-value<0.05? {p_value<0.05}')"
      ],
      "metadata": {
        "id": "i4ifo54GIeiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "nbG9-9HRImxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert gender to binary classification\n",
        "df = pd.get_dummies(df,columns=['gender'],drop_first=True)\n",
        "#We will get the time between transactions for each card\n",
        "#Time=0 for every first transaction and time will be represented in hours.\n",
        "df.sort_values(['cc_num', 'trans_date_trans_time'],inplace=True)\n",
        "df['hours_diff_bet_trans']=((df.groupby('cc_num')[['trans_date_trans_time']].diff())/np.timedelta64(1,'h'))\n",
        "df.loc[df['hours_diff_bet_trans'].isna(),'hours_diff_bet_trans'] = 0\n",
        "df['hours_diff_bet_trans'] = df['hours_diff_bet_trans'].astype(int)\n",
        "# x_0=df.groupby('is_fraud')['hours_diff_bet_trans'].mean().values[0]\n",
        "# x_1=df.groupby('is_fraud')['hours_diff_bet_trans'].mean().values[1]\n",
        "# std_0=df.groupby('is_fraud')['hours_diff_bet_trans'].std().values[0]\n",
        "# std_1=df.groupby('is_fraud')['hours_diff_bet_trans'].std().values[1]\n",
        "# n_0=df.groupby('is_fraud')['hours_diff_bet_trans'].count().values[0]\n",
        "# n_1=df.groupby('is_fraud')['hours_diff_bet_trans'].count().values[1]\n",
        "# numerator = x_0 - x_1\n",
        "# domin = np.sqrt(std_0**2/n_0 + std_1**2/n_1)\n",
        "# t_stat=numerator/domin\n",
        "# p_val = 2*(1-t.cdf(abs(t_stat),df=n_0+n_1-2))\n",
        "# print(t_stat,p_val)\n",
        "#----------------------\n",
        "#The power of pingouin library!\n",
        "print(pingouin.ttest(df[df['is_fraud'] == 0]['hours_diff_bet_trans'],\n",
        "              df[df['is_fraud'] == 1]['hours_diff_bet_trans'],\n",
        "              alternative='two-sided')[['T','p-val']])\n",
        "sns.barplot(data=df,x='is_fraud',y='hours_diff_bet_trans',ci=None)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "THPl9AjdItJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Since p-val < 0.05,we reject the null hypothesis.\n",
        "#The mean of hours is significantly different between frauds and non-frauds transactions\n",
        "#Make day feature numerical\n",
        "df['day'] = df['trans_date_trans_time'].dt.weekday\n",
        "#Handling and extracting features from cc_num\n",
        "freq = df.groupby('cc_num').size()\n",
        "df['cc_freq'] = df['cc_num'].apply(lambda x : freq[x])\n",
        "df[['cc_num','cc_freq']].head()"
      ],
      "metadata": {
        "id": "0XJBmx9TI5pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We got freq for each cc_num\n",
        "def hist_show(col):\n",
        "    fig,axs = plt.subplots(1,2,sharex=True)\n",
        "    for i in [0,1]:\n",
        "        sns.histplot(df[df[\"is_fraud\"]==i][col], bins=6,ax=axs[i])\n",
        "hist_show('cc_freq')"
      ],
      "metadata": {
        "id": "U7_txNCHJH6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def class_det(x):\n",
        "    for idx,val in enumerate(list(range(800,5000,800))):\n",
        "        if x < val:\n",
        "            return idx+1\n",
        "df['cc_freq_class'] = df['cc_freq'].apply(class_det)\n",
        "print(df['cc_freq_class'].unique())"
      ],
      "metadata": {
        "id": "w6Mdl_zZJQq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_show('cc_freq_class')"
      ],
      "metadata": {
        "id": "tonQu8waJdKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now clearly frauds occurs more in credit cards with less use (new ones) and for genuine transactions, it follows a normal distribution.¶\n",
        "#Drop unecessary columns\n",
        "df.drop(columns=['cc_num','trans_date_trans_time','city_pop'],inplace=True)\n",
        "df.columns\n"
      ],
      "metadata": {
        "id": "xmWu9WiuJgRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reorder columns\n",
        "df = df[['cc_freq','cc_freq_class','city','job','age','gender_M','merchant', 'category',\n",
        "         'distance_km','month','day','hour','hours_diff_bet_trans','amt','is_fraud','split']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "W-y5ucZaJqwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will encode ('city','job','merchant', 'category') preparing for our model using WOE encoder\n",
        "for col in ['city','job','merchant', 'category']:\n",
        "    df[col] = WOEEncoder().fit_transform(df[col],df['is_fraud'])\n",
        "# WOE > 0: The category is more likely associated with (fraud)\n",
        "# WOE < 0: The category is more likely associated with (non-fraud)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Ef6aKFwUJxi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = df[df['split']=='train'].drop(['split','is_fraud'],axis=1)\n",
        "y_train = df[df['split']=='train']['is_fraud']\n",
        "x_test = df[df['split']=='test'].drop(['split','is_fraud'],axis=1)\n",
        "y_test = df[df['split']=='test']['is_fraud']\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.pie([len(x_train),len(x_test)],autopct='%.2f%%'\n",
        "        ,textprops={'color':'white'},explode=[0,0.05],shadow=True)\n",
        "plt.legend(['Train','Test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2XxXEajfJ9yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling outliers\n",
        "x_train.select_dtypes(include='number').columns"
      ],
      "metadata": {
        "id": "7_iRnY0TKFZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets={'x_train':x_train,'x_test':x_test}\n",
        "cols = ['hours_diff_bet_trans', 'amt']\n",
        "#Outliers in train data before scaling\n",
        "def count_outliers(l:list):\n",
        "    for col in l:\n",
        "        print(f'Outliers In {col}:',len(detect_outliers(x_train,0,[col])))\n",
        "def boxplot_outliers(ds:dict):\n",
        "    plt.figure(figsize=(18,8))\n",
        "    c=1\n",
        "    for _,df_x in ds.items():\n",
        "        for col in ['hours_diff_bet_trans', 'amt']:\n",
        "            plt.subplot(2,2,c)\n",
        "            df_x[col].plot(kind='box',vert=False)\n",
        "            c+=1\n",
        "    plt.suptitle('Detecting Outliers In Train|Test Data',fontsize=20)\n",
        "    plt.tight_layout()\n",
        "count_outliers(cols)\n",
        "boxplot_outliers(datasets)"
      ],
      "metadata": {
        "id": "mMSnsFl9KLsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying log scale\n",
        "for col in cols:\n",
        "    x_train[col] = np.log1p(x_train[col])\n",
        "    x_test[col] = np.log1p(x_test[col])\n",
        "count_outliers(cols)\n",
        "boxplot_outliers(datasets)"
      ],
      "metadata": {
        "id": "FJYNVnf7KVr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Note:-\n",
        "#Logistic Regression often benefits from feature scaling.Since the algorithm uses the weights assigned to features during\n",
        "#training, and having features on similar scales can help the optimization process converge faster.\n",
        "#While Decision Trees, including Random Forest (an ensemble of decision trees), are generally not sensitive to the scale of the\n",
        "#features.They make decisions based on splitting criteria and don't rely on the absolute values of the features.\n",
        "scaler = StandardScaler().fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "ysLnTFQXKfhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's try our model without handling the imbalance data of fraud feature\n",
        "evl_models = {'Logistic Regression':LogisticRegression(random_state=10),\n",
        "          'Decision Tree':DecisionTreeClassifier(random_state=10),\n",
        "          'Random Forest':RandomForestClassifier(random_state=10)}\n",
        "def evl_model(xtrain,ytrain,xtest,ytest):\n",
        "    sns.set(rc={'figure.figsize':(18,6)})\n",
        "    i=0\n",
        "    for name,model in evl_models.items():\n",
        "        fig,axs=plt.subplots(1,2)\n",
        "        print('Model : '+name)\n",
        "        print('_'*30)\n",
        "        start=time()\n",
        "        model.fit(xtrain,ytrain)\n",
        "        y_pred = model.predict(xtest)\n",
        "        end=time()\n",
        "        #Confusion Matrix\n",
        "        cm = confusion_matrix(ytest,y_pred,labels=model.classes_)\n",
        "        cmd = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
        "        cmd.plot(colorbar=False,ax=axs[i])\n",
        "        axs[i].grid(False)\n",
        "        #AUC-ROC Curve\n",
        "        y_proba = model.predict_proba(xtest)\n",
        "        fpr, tpr, _ = roc_curve(ytest, y_proba[:, 1])\n",
        "        roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot(ax=axs[i+1])\n",
        "        axs[i+1].plot([0, 1], [0, 1], color = 'g')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        #We focus on recall=TP/TP+FN\n",
        "        #such that it's the score that model predict(non-fraud) while it's fraud.\n",
        "        print('Recall Score: ',recall_score(ytest,y_pred))\n",
        "        print('Precision: ',precision_score(ytest,y_pred))\n",
        "        print('F1-Score: ',f1_score(ytest,y_pred))\n",
        "        print('Accuracy Score: ',accuracy_score(ytest,y_pred))\n",
        "        print('AUC Score: ',roc_auc_score(ytest,y_proba[:,1]))\n",
        "        print('Running Time : ',round((end-start)/60.0,2),'Mins')\n",
        "        print('*'*30)\n",
        "evl_model(x_train,y_train,x_test,y_test)\n"
      ],
      "metadata": {
        "id": "J6g4nXnDKoy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's apply SMOTE over sampling to make balance between fraud and non-fraud data and see if there is a significant different\n",
        "#Between the accuracies or not\n",
        "smote = SMOTE()\n",
        "x_train,y_train = smote.fit_resample(x_train,y_train)\n",
        "y_train.value_counts().plot(kind='pie',figsize=(4,4),autopct='%.2f%%',textprops={'color':'white'},labels=['Fraud','Non-Fraud'],legend=True)"
      ],
      "metadata": {
        "id": "ZHEgzkfsK---"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evl_model(x_train,y_train,x_test,y_test)"
      ],
      "metadata": {
        "id": "V9Lt4fK0LPL2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}